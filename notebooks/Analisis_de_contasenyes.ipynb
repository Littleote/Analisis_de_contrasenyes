{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5695a185",
   "metadata": {},
   "source": [
    "# CAS KAGGLE: Analisis de la seguretat de contrasenyes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55bbb0d",
   "metadata": {},
   "source": [
    "### David Candela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b3810",
   "metadata": {},
   "source": [
    "# Introducció\n",
    "\n",
    "Que faig i perquè."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2258b5",
   "metadata": {},
   "source": [
    "# 1. Netejar i visualitzar el dataset\n",
    "\n",
    "https://www.kaggle.com/bhavikbb/password-strength-classifier-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "Minuscules = [chr(c) for c in range(ord('a'), ord('z') + 1)]\n",
    "Majuscules = [chr(c) for c in range(ord('A'), ord('Z') + 1)]\n",
    "Xifres = [str(i) for i in range(10)]\n",
    "Especials = ['.', ';', '-', '_', '+', '*', '<', '>', '[', ']', '{', '}', \\\n",
    "             '(', ')', '@', '#', '$', '%', '&', '/', '\\\\', '?', '!', '=', \\\n",
    "             '^', '~', ' ']\n",
    "CaractersValids = Minuscules + Majuscules + Xifres + Especials\n",
    "TipusCaracters = dict()\n",
    "TipusCaracters.update({c: \"Minuscules\" for c in Minuscules})\n",
    "TipusCaracters.update({c: \"Majuscules\" for c in Majuscules})\n",
    "TipusCaracters.update({c: \"Xifres\" for c in Xifres})\n",
    "TipusCaracters.update({c: \"Especials\" for c in Especials})\n",
    "\n",
    "def isValid(contrasenya):\n",
    "    try:\n",
    "        # Treure les contrasenyes amb caracters que no consideri valids\n",
    "        #   ja que no importa el format de descodificació especificat,\n",
    "        #   Python es incapaç de llegir correctament tots els diferents caràcters\n",
    "        #   caracters i sempre en surten de l'estil '\\x03', '\\x0f', '\\x8d'\n",
    "        #   o també §, ¶, ­, þ, ¤, ...\n",
    "        return all(c in CaractersValids for c in contrasenya)\n",
    "    except:\n",
    "        # Truere les contrasenyes que Pandas converteixi continuament a float\n",
    "        #   tot i que s'ha marcat la columna de passwords com strings\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e882b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = '../data/'\n",
    "data_name = 'data.csv'\n",
    "clean_name = 'clean_data.csv'\n",
    "data_file = path + data_name\n",
    "clean_file = path + clean_name\n",
    "regenerate_file = False\n",
    "\n",
    "if regenerate_file or not os.path.isfile(clean_file):\n",
    "    assert os.path.isfile(data_file)\n",
    "    # Saltarse les files on les dades no estiguin ben formategades\n",
    "    dataset = pd.read_csv(data_file, on_bad_lines='skip', encoding='utf-8', dtype={'password': str, 'strength': np.int64})\n",
    "    # Treure les dades que contenen caracters que no acceptem\n",
    "    dataset = dataset[dataset.apply(lambda s: isValid(s['password']), axis=1)]\n",
    "    # Guardar el nou dataset a un fitxer apart\n",
    "    dataset.to_csv(clean_file, index=False)\n",
    "    \n",
    "dataset = pd.read_csv(clean_file)\n",
    "dades = dataset.values\n",
    "contrasenyes = dades[:,0]\n",
    "dades_proteccio = dades[:,1].astype(np.int64)\n",
    "noms = dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af464d3",
   "metadata": {},
   "source": [
    "# 2. Extreure dades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87fb03",
   "metadata": {},
   "source": [
    "## Predictabilitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recompte(contrasenya, individual, predictabilitat):\n",
    "    c_ = ''\n",
    "    for c in contrasenya:\n",
    "        predictabilitat[c_][c] += 1\n",
    "        predictabilitat[c_]['total'] += 1\n",
    "        individual[c] += 1\n",
    "        individual['total'] += 1\n",
    "        c_ = c\n",
    "\n",
    "individual = {c:0 for c in CaractersValids + ['total']}\n",
    "predictabilitat = {c:{c:1 if not c == 'total' else len(CaractersValids) for c in CaractersValids + ['total']} for c in CaractersValids + ['']}\n",
    "\n",
    "for p in dades[:,0]:\n",
    "    recompte(p, individual, predictabilitat)\n",
    "\n",
    "individual_total = individual['total']\n",
    "predictabilitat_total = {c:predictabilitat[c]['total'] for c in predictabilitat.keys()}\n",
    "\n",
    "individual.pop('total')\n",
    "for k in predictabilitat.keys():\n",
    "    predictabilitat[k].pop('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "\n",
    "plt.subplots(figsize=(20, 18))\n",
    "plt.bar(individual.keys(), individual.values())\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(figsize=(20, 18))\n",
    "sns.heatmap([[e for e in d.values()] for d in predictabilitat.values()], \\\n",
    "            xticklabels=CaractersValids, yticklabels=CaractersValids + ['inici'], square=True, norm=LogNorm())\n",
    "plt.xlabel(\"Segon\")\n",
    "plt.ylabel(\"Primer\")\n",
    "plt.title(\"Sequencies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089e560",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def probabilitat_caracters(x):\n",
    "    res = 1\n",
    "    valid = 0\n",
    "    for c in x:\n",
    "        res *= individual.get(c, 1)\n",
    "        valid += 1\n",
    "    return res / (individual_total ** valid)\n",
    "\n",
    "def probabilitat_sequencia(x):\n",
    "    res = 1\n",
    "    c_ = ''\n",
    "    for c in x:\n",
    "        if c not in CaractersValids:\n",
    "            continue\n",
    "        res *= predictabilitat[c_][c] / predictabilitat_total[c_]\n",
    "        c_ = c\n",
    "    return res\n",
    "\n",
    "def aleatorietat(x):\n",
    "    res = 1\n",
    "    c_ = ''\n",
    "    for c in x:\n",
    "        if c not in CaractersValids:\n",
    "            continue\n",
    "        res *= individual[c] / predictabilitat[c_][c] * predictabilitat_total[c_] / individual_total\n",
    "        c_ = c\n",
    "    return res\n",
    "\n",
    "def llargada(x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "dades_caracters = np.vectorize(probabilitat_caracters)(contrasenyes)\n",
    "dades_sequencia = np.vectorize(probabilitat_sequencia)(contrasenyes)\n",
    "dades_aleatorietat = np.vectorize(aleatorietat)(contrasenyes)\n",
    "dades_llargada = np.vectorize(llargada)(contrasenyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dades_predictabilitat = np.stack((dades_caracters, dades_sequencia, dades_aleatorietat, dades_llargada, dades_proteccio), axis=-1)\n",
    "DP = dades_predictabilitat\n",
    "dfDP = pd.DataFrame(data=DP, columns=['caracters', 'sequencia', 'aleatorietat', 'llargada', 'proteccio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=dfDP, x=\"caracters\", hue=\"proteccio\", multiple=\"layer\", log_scale=True, binrange=[-39, -7], element=\"poly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292135b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=dfDP, x=\"sequencia\", hue=\"proteccio\", multiple=\"layer\", log_scale=True, binrange=[-36, -5], element=\"poly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73070de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=dfDP, x=\"aleatorietat\", hue=\"proteccio\", multiple=\"layer\", log_scale=True, binrange=[-10, 6], element=\"poly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=dfDP, x=\"llargada\", hue=\"proteccio\", multiple=\"stack\", discrete=True, binrange=[1, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8042c9e",
   "metadata": {},
   "source": [
    "### Probar eficacia de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subset(X, y, p=1, index=None, returnUnusedIndex=False):\n",
    "    if index is not None:\n",
    "        l = len(index)\n",
    "        idx = returnUnusedIndex\n",
    "    else:\n",
    "        l = len(y)\n",
    "        index = np.array([i for i in range(l)])\n",
    "        idx = False\n",
    "    if p == 1:\n",
    "        new_X = X[index]\n",
    "        new_y = y[index]\n",
    "        index = np.array([])\n",
    "        unique, counts = np.unique(new_y, return_counts=True)\n",
    "        values = {u: l / len(unique) / c for u, c in zip(unique, counts)}\n",
    "        ret = (new_X, new_y, np.array([values[yi] for yi in new_y]))\n",
    "    elif type(p) == list:\n",
    "        subsets = []\n",
    "        f = 1\n",
    "        for pi in p:\n",
    "            elem, index = make_subset(X, y, p=pi / f, index=index, returnUnusedIndex=True)\n",
    "            subsets.append(elem)\n",
    "            f -= pi\n",
    "        subsets.append(make_subset(X, y, index=index))\n",
    "        ret = (subsets)\n",
    "    else:\n",
    "        new_l = int(l * p)\n",
    "        ind = np.random.choice(index, new_l, replace=False)\n",
    "        index = np.setdiff1d(index, ind)\n",
    "        new_X = X[ind]\n",
    "        new_y = y[ind]\n",
    "        unique, counts = np.unique(new_y, return_counts=True)\n",
    "        values = {u: new_l / len(unique) / c for u, c in zip(unique, counts)}\n",
    "        ret = (new_X, new_y, np.array([values[yi] for yi in new_y]))\n",
    "    if idx:\n",
    "        return ret, index\n",
    "    else:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac416db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class oneVsRest:\n",
    "    def __init__(self, model, **kwargs):\n",
    "        self.model = model\n",
    "        self.modelArgs = kwargs\n",
    "        \n",
    "    def fit(self, x, y, w=None):\n",
    "        yTo0 = np.copy(y)\n",
    "        yTo0[yTo0 > 0] = -1\n",
    "        yTo0[yTo0 != -1] = 1\n",
    "        self.classTo0 = self.model(**self.modelArgs)\n",
    "        self.classTo0.fit(x, yTo0, sample_weight=w)\n",
    "        yTo1 = np.copy(y)\n",
    "        yTo1[yTo1 > 1] = -1\n",
    "        yTo1[yTo1 != -1] = 1\n",
    "        self.classTo1 = self.model(**self.modelArgs)\n",
    "        self.classTo1.fit(x, yTo1, sample_weight=w)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return (2 - self.classTo0.predict(x) - self.classTo1.predict(x)) / 2\n",
    "\n",
    "class LogPipe:\n",
    "    err = 1e-200\n",
    "    def __init__ (self, columns):\n",
    "        self.column_transform = columns\n",
    "    \n",
    "    def fit (self, X, **args):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, copy=True):\n",
    "        if copy == True:\n",
    "            X_tr = np.copy(X)\n",
    "        else:\n",
    "            X_tr = X\n",
    "        X_tr[:, self.column_transform] = np.log(X_tr[:, self.column_transform] + LogPipe.err)\n",
    "        return X_tr\n",
    "    \n",
    "    def fit_transform(self, X, y=None, copy=True, **args):\n",
    "        return self.transform(X, copy)\n",
    "\n",
    "def regression(x, y, model=linear_model.LogisticRegression, w=None, **kwargs):\n",
    "    # Creem un objecte de regressió de sklearn\n",
    "    regr = oneVsRest(model, **kwargs)\n",
    "\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(x, y, w=w)\n",
    "\n",
    "    # Retornem el model entrenat\n",
    "    return regr\n",
    "\n",
    "def visualize_confusion_matrix(y_pred, y_real):\n",
    "    #mostra la matriu de confusió\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "    plt.subplots(figsize=(10, 6))\n",
    "    sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "atribDP = dfDP[['caracters', 'sequencia', 'aleatorietat', 'llargada']].values\n",
    "objDP = dfDP['proteccio'].values\n",
    "\n",
    "dades_t, objectiu_t, w_t = make_subset(atribDP, objDP, .2)\n",
    "dades_cv, objectiu_cv, w_cv = make_subset(atribDP, objDP, 1)\n",
    "log_norm = LogPipe([0, 1, 2]).fit(dades_t)\n",
    "norm = preprocessing.StandardScaler().fit(log_norm.transform(dades_t))\n",
    "r = regression(norm.transform(log_norm.transform(dades_t)), objectiu_t, w=w_t, model=svm.LinearSVC, max_iter=1e6)\n",
    "# linear_model.LogisticRegression\n",
    "# svm.LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "prediccio = r.predict(norm.transform(log_norm.transform(dades_cv)))\n",
    "print(f'Accuracy: {sum(objectiu_cv==prediccio) / len(prediccio)}')\n",
    "print(f'Weighted accuracy: {sum(w_cv * (objectiu_cv==prediccio)) / len(prediccio)}')\n",
    "visualize_confusion_matrix(prediccio, objectiu_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe530b",
   "metadata": {},
   "source": [
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb799824",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f'Per nivell de protecció {i} la llargada es troba entre {min(dades_llargada[dades_proteccio == i])} i {max(dades_llargada[dades_proteccio == i])}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "prediccio = np.array([0 if len(x) < 8 else (2 if len(x) > 13 else 1) for x in contrasenyes])\n",
    "visualize_confusion_matrix(prediccio, dades_proteccio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7f157",
   "metadata": {},
   "source": [
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b06d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "atribDP = dfDP[['caracters', 'sequencia', 'aleatorietat']].values\n",
    "objDP = dfDP['proteccio'].values\n",
    "\n",
    "dades_t, objectiu_t, w_t = make_subset(atribDP, objDP, .2)\n",
    "dades_cv, objectiu_cv, w_cv = make_subset(atribDP, objDP, 1)\n",
    "log_norm = LogPipe([0, 1, 2]).fit(dades_t)\n",
    "norm = preprocessing.StandardScaler().fit(log_norm.transform(dades_t))\n",
    "r = regression(norm.transform(log_norm.transform(dades_t)), objectiu_t, w=w_t, model=linear_model.LogisticRegression, max_iter=1e6)\n",
    "# linear_model.LogisticRegression\n",
    "# svm.LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727ba23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "prediccio = r.predict(norm.transform(log_norm.transform(dades_cv)))\n",
    "print(f'Accuracy: {sum(objectiu_cv==prediccio) / len(prediccio)}')\n",
    "print(f'Weighted accuracy: {sum(w_cv * (objectiu_cv==prediccio)) / len(prediccio)}')\n",
    "visualize_confusion_matrix(prediccio, objectiu_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17614bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('log', LogPipe([0, 1, 2])), ('scaler', preprocessing.StandardScaler()), ('model', linear_model.LogisticRegression())])\n",
    "\n",
    "atribDP = dfDP[['caracters', 'sequencia', 'aleatorietat']].values\n",
    "objDP = dfDP['proteccio'].values\n",
    "\n",
    "Y_cv, W_cv, prediccio = [], [], []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(objDP):\n",
    "    x_t, y_t, w_t = make_subset(atribDP[train_index], objDP[train_index])\n",
    "    x_cv, y_cv, w_cv = make_subset(atribDP[test_index], objDP[test_index])\n",
    "    pipe.fit(x_t, y_t, model__sample_weight=w_t) # model__sample_weight=w_t\n",
    "\n",
    "    Y_cv.append(y_cv)\n",
    "    W_cv.append(w_cv)\n",
    "    prediccio.append(pipe.predict(x_cv))\n",
    "    \n",
    "Y_cv = np.concatenate(Y_cv)\n",
    "W_cv = np.concatenate(W_cv)\n",
    "prediccio = np.concatenate(prediccio)\n",
    "\n",
    "print(f'Accuracy: {sum(Y_cv==prediccio) / len(prediccio)}')\n",
    "print(f'Weighted accuracy: {sum(W_cv * (Y_cv==prediccio)) / len(prediccio)}')\n",
    "visualize_confusion_matrix(prediccio, Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227dae77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('log', LogPipe([0, 1, 2])), ('scaler', preprocessing.StandardScaler()), ('model', linear_model.LinearRegression())])\n",
    "\n",
    "atribDP = dfDP[['caracters', 'sequencia', 'aleatorietat']].values\n",
    "objDP = dfDP['llargada'].values\n",
    "\n",
    "Y_cv, prediccio = [], []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(objDP):\n",
    "    x_t, y_t = atribDP[train_index], objDP[train_index]\n",
    "    x_cv, y_cv = atribDP[test_index], objDP[test_index]\n",
    "    pipe.fit(x_t, y_t)\n",
    "\n",
    "    Y_cv.append(y_cv)\n",
    "    prediccio.append(pipe.predict(x_cv))\n",
    "    \n",
    "Y_cv = np.concatenate(Y_cv)\n",
    "prediccio = np.concatenate(prediccio)\n",
    "\n",
    "print(f'MSE: {sum((Y_cv - prediccio) ** 2) / len(prediccio)}')\n",
    "fig = plt.figure()\n",
    "plt.xlim([0,50])\n",
    "plt.ylim([0,50])\n",
    "ax = plt.gca()\n",
    "plt.scatter(x=prediccio, y=Y_cv, alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771972b9",
   "metadata": {},
   "source": [
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b127a14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mitja_caracters(x):\n",
    "    res = 0\n",
    "    valid = 0\n",
    "    for c in x:\n",
    "        res += np.log(individual.get(c, 1))\n",
    "        valid += 1\n",
    "    return np.exp(res / valid) / individual_total if valid > 0 else 1\n",
    "\n",
    "def mitja_sequencia(x):\n",
    "    res = 1\n",
    "    c_ = ''\n",
    "    valid = 0\n",
    "    for c in x:\n",
    "        if c not in CaractersValids:\n",
    "            continue\n",
    "        res *= predictabilitat[c_][c] / predictabilitat_total[c_]\n",
    "        c_ = c\n",
    "        valid += 1\n",
    "    return res ** (1 / valid) if valid > 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dades_mitja_caracters = np.vectorize(mitja_caracters)(contrasenyes)\n",
    "dades_mitja_sequencia = np.vectorize(mitja_sequencia)(contrasenyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8635b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dades_predictabilitat = np.stack((dades_caracters, dades_mitja_caracters, dades_sequencia, dades_mitja_sequencia, dades_aleatorietat, dades_llargada, dades_proteccio), axis=-1)\n",
    "DP = dades_predictabilitat\n",
    "dfDP = pd.DataFrame(data=DP, columns=['caracters', 'mitja caracters', 'sequencia', 'mitja sequencia', 'aleatorietat', 'llargada', 'proteccio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=dfDP, x=\"mitja caracters\", hue=\"proteccio\", multiple=\"layer\", log_scale=True, binrange=[-2.3, -1.3], element=\"poly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=dfDP, x=\"mitja sequencia\", hue=\"proteccio\", multiple=\"layer\", log_scale=True, binrange=[-2.2, -0.8], element=\"poly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c408e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('log', LogPipe([0, 1, 2])), ('scaler', preprocessing.StandardScaler()), ('model', linear_model.LogisticRegression())])\n",
    "\n",
    "atribDP = dfDP[['mitja caracters', 'mitja sequencia', 'aleatorietat']].values\n",
    "objDP = dfDP['proteccio'].values\n",
    "\n",
    "Y_cv, W_cv, prediccio = [], [], []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(objDP):\n",
    "    x_t, y_t, w_t = make_subset(atribDP[train_index], objDP[train_index])\n",
    "    x_cv, y_cv, w_cv = make_subset(atribDP[test_index], objDP[test_index])\n",
    "    pipe.fit(x_t, y_t, model__sample_weight=w_t) # model__sample_weight=w_t\n",
    "\n",
    "    Y_cv.append(y_cv)\n",
    "    W_cv.append(w_cv)\n",
    "    prediccio.append(pipe.predict(x_cv))\n",
    "    \n",
    "Y_cv = np.concatenate(Y_cv)\n",
    "W_cv = np.concatenate(W_cv)\n",
    "prediccio = np.concatenate(prediccio)\n",
    "\n",
    "print(f'Accuracy: {sum(Y_cv==prediccio) / len(prediccio)}')\n",
    "print(f'Weighted accuracy: {sum(W_cv * (Y_cv==prediccio)) / len(prediccio)}')\n",
    "visualize_confusion_matrix(prediccio, Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec60a7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('log', LogPipe([0, 1, 2])), ('scaler', preprocessing.StandardScaler()), ('model', linear_model.LinearRegression())])\n",
    "\n",
    "atribDP = dfDP[['mitja caracters', 'mitja sequencia', 'aleatorietat']].values\n",
    "objDP = dfDP['llargada'].values\n",
    "\n",
    "Y_cv, prediccio = [], []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(objDP):\n",
    "    x_t, y_t = atribDP[train_index], objDP[train_index]\n",
    "    x_cv, y_cv = atribDP[test_index], objDP[test_index]\n",
    "    pipe.fit(x_t, y_t)\n",
    "\n",
    "    Y_cv.append(y_cv)\n",
    "    prediccio.append(pipe.predict(x_cv))\n",
    "    \n",
    "Y_cv = np.concatenate(Y_cv)\n",
    "prediccio = np.concatenate(prediccio)\n",
    "\n",
    "print(f'MSE: {sum((Y_cv - prediccio) ** 2) / len(prediccio)}')\n",
    "fig = plt.figure()\n",
    "plt.xlim([0,50])\n",
    "plt.ylim([0,50])\n",
    "ax = plt.gca()\n",
    "plt.scatter(x=prediccio, y=Y_cv, alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825f336",
   "metadata": {},
   "source": [
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92363b3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mitja_cadena(x):\n",
    "    canvis = 0\n",
    "    valid = 0\n",
    "    ultim = \"Cap\"\n",
    "    for c in x:\n",
    "        actual = TipusCaracters.get(c, \"Cap\")\n",
    "        if actual == \"Cap\":\n",
    "            continue\n",
    "        elif not actual == ultim:\n",
    "            ultim = actual\n",
    "            canvis += 1\n",
    "        valid += 1\n",
    "    return valid / canvis if not canvis == 0 else 0\n",
    "\n",
    "def ponderacio_cadena(x):\n",
    "    valid = 0\n",
    "    S, s = 0, 1\n",
    "    ultim = \"Cap\"\n",
    "    for c in x:\n",
    "        actual = TipusCaracters.get(c, \"Cap\")\n",
    "        if actual == \"Cap\":\n",
    "            continue\n",
    "        elif not actual == ultim:\n",
    "            ultim = actual\n",
    "            s = 1\n",
    "        else:\n",
    "            s += 2\n",
    "        S += s\n",
    "        valid += 1\n",
    "    return S / valid if not valid == 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dades_mitja_cadena = np.vectorize(mitja_cadena)(contrasenyes)\n",
    "dades_ponderacio_cadena = np.vectorize(ponderacio_cadena)(contrasenyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3129abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dades_predictabilitat = np.stack((dades_caracters, dades_mitja_caracters, dades_sequencia, dades_mitja_sequencia, dades_aleatorietat, dades_llargada, dades_mitja_cadena, dades_ponderacio_cadena, dades_proteccio), axis=-1)\n",
    "DP = dades_predictabilitat\n",
    "dfDP = pd.DataFrame(data=DP, columns=['caracters', 'mitja caracters', 'sequencia', 'mitja sequencia', 'aleatorietat', 'llargada', 'mitja cadena', 'ponderacio cadena', 'proteccio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8695449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=dfDP, x=\"mitja cadena\", hue=\"proteccio\", multiple=\"stack\", binrange=[1, 10])\n",
    "plt.show()\n",
    "sns.histplot(data=dfDP, x=\"mitja cadena\", hue=\"proteccio\", multiple=\"layer\", binwidth=1, binrange=[1, 10], element=\"poly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e457624",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=dfDP, x=\"ponderacio cadena\", hue=\"proteccio\", multiple=\"stack\", binrange=[1, 10])\n",
    "plt.show()\n",
    "sns.histplot(data=dfDP, x=\"ponderacio cadena\", hue=\"proteccio\", multiple=\"layer\", binwidth=1, binrange=[0, 10], element=\"poly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd9b71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('scaler', preprocessing.StandardScaler()), ('model', linear_model.LogisticRegression())])\n",
    "\n",
    "atribDP = dfDP[['mitja cadena', 'ponderacio cadena']].values\n",
    "objDP = dfDP['proteccio'].values\n",
    "\n",
    "Y_cv, W_cv, prediccio = [], [], []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(objDP):\n",
    "    x_t, y_t, w_t = make_subset(atribDP[train_index], objDP[train_index])\n",
    "    x_cv, y_cv, w_cv = make_subset(atribDP[test_index], objDP[test_index])\n",
    "    pipe.fit(x_t, y_t, model__sample_weight=w_t) # model__sample_weight=w_t\n",
    "\n",
    "    Y_cv.append(y_cv)\n",
    "    W_cv.append(w_cv)\n",
    "    prediccio.append(pipe.predict(x_cv))\n",
    "    \n",
    "Y_cv = np.concatenate(Y_cv)\n",
    "W_cv = np.concatenate(W_cv)\n",
    "prediccio = np.concatenate(prediccio)\n",
    "\n",
    "print(f'Accuracy: {sum(Y_cv==prediccio) / len(prediccio)}')\n",
    "print(f'Weighted accuracy: {sum(W_cv * (Y_cv==prediccio)) / len(prediccio)}')\n",
    "visualize_confusion_matrix(prediccio, Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6754e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('scaler', preprocessing.StandardScaler()), ('model', linear_model.LinearRegression())])\n",
    "\n",
    "atribDP = dfDP[['mitja cadena', 'ponderacio cadena']].values\n",
    "objDP = dfDP['llargada'].values\n",
    "\n",
    "Y_cv, prediccio = [], []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(objDP):\n",
    "    x_t, y_t = atribDP[train_index], objDP[train_index]\n",
    "    x_cv, y_cv = atribDP[test_index], objDP[test_index]\n",
    "    pipe.fit(x_t, y_t)\n",
    "\n",
    "    Y_cv.append(y_cv)\n",
    "    prediccio.append(pipe.predict(x_cv))\n",
    "    \n",
    "Y_cv = np.concatenate(Y_cv)\n",
    "prediccio = np.concatenate(prediccio)\n",
    "\n",
    "print(f'MSE: {sum((Y_cv - prediccio) ** 2) / len(prediccio)}')\n",
    "fig = plt.figure()\n",
    "plt.xlim([0,50])\n",
    "plt.ylim([0,50])\n",
    "ax = plt.gca()\n",
    "plt.scatter(x=prediccio, y=Y_cv, alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6934f3b3",
   "metadata": {},
   "source": [
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e538e85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('log', LogPipe([0, 1, 2])), ('scaler', preprocessing.StandardScaler()), ('model', linear_model.LogisticRegression())])\n",
    "\n",
    "atribDP = dfDP[['mitja caracters', 'mitja sequencia', 'aleatorietat', 'mitja cadena', 'ponderacio cadena']].values\n",
    "objDP = dfDP['proteccio'].values\n",
    "\n",
    "Y_cv, W_cv, prediccio = [], [], []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(objDP):\n",
    "    x_t, y_t, w_t = make_subset(atribDP[train_index], objDP[train_index])\n",
    "    x_cv, y_cv, w_cv = make_subset(atribDP[test_index], objDP[test_index])\n",
    "    pipe.fit(x_t, y_t, model__sample_weight=w_t) # model__sample_weight=w_t\n",
    "\n",
    "    Y_cv.append(y_cv)\n",
    "    W_cv.append(w_cv)\n",
    "    prediccio.append(pipe.predict(x_cv))\n",
    "    \n",
    "Y_cv = np.concatenate(Y_cv)\n",
    "W_cv = np.concatenate(W_cv)\n",
    "prediccio = np.concatenate(prediccio)\n",
    "\n",
    "print(f'Accuracy: {sum(Y_cv==prediccio) / len(prediccio)}')\n",
    "print(f'Weighted accuracy: {sum(W_cv * (Y_cv==prediccio)) / len(prediccio)}')\n",
    "visualize_confusion_matrix(prediccio, Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002efbd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('log', LogPipe([0, 1, 2])), ('scaler', preprocessing.StandardScaler()), ('model', linear_model.LinearRegression())])\n",
    "\n",
    "atribDP = dfDP[['mitja caracters', 'mitja sequencia', 'aleatorietat', 'mitja cadena', 'ponderacio cadena']].values\n",
    "objDP = dfDP['llargada'].values\n",
    "\n",
    "Y_cv, prediccio = [], []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(objDP):\n",
    "    x_t, y_t = atribDP[train_index], objDP[train_index]\n",
    "    x_cv, y_cv = atribDP[test_index], objDP[test_index]\n",
    "    pipe.fit(x_t, y_t)\n",
    "\n",
    "    Y_cv.append(y_cv)\n",
    "    prediccio.append(pipe.predict(x_cv))\n",
    "    \n",
    "Y_cv = np.concatenate(Y_cv)\n",
    "prediccio = np.concatenate(prediccio)\n",
    "\n",
    "print(f'MSE: {sum((Y_cv - prediccio) ** 2) / len(prediccio)}')\n",
    "fig = plt.figure()\n",
    "plt.xlim([0,50])\n",
    "plt.ylim([0,50])\n",
    "ax = plt.gca()\n",
    "plt.scatter(x=prediccio, y=Y_cv, alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed127997",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([('log', LogPipe([0, 1, 2])), ('scaler', preprocessing.StandardScaler()), ('model', linear_model.LogisticRegression())])\n",
    "\n",
    "atribDP = dfDP[['mitja caracters', 'mitja sequencia', 'aleatorietat', 'mitja cadena', 'ponderacio cadena']].values\n",
    "objDP = dfDP['proteccio'].values\n",
    "\n",
    "dades_t, objectiu_t, w_t = make_subset(atribDP, objDP)\n",
    "pipe2.fit(dades_t, objectiu_t, model__sample_weight=w_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "password = widgets.Text()\n",
    "warning = widgets.Label()\n",
    "strength1 = widgets.Label()\n",
    "strength2 = widgets.Label()\n",
    "\n",
    "def format2(x):\n",
    "    return np.array([[mitja_caracters(x), mitja_sequencia(x), aleatorietat(x), mitja_cadena(x), ponderacio_cadena(x)]])\n",
    "\n",
    "def on_value_change(change):\n",
    "    warning.value = ''\n",
    "    if not isValid(change['new']):\n",
    "        password.value = change['old']\n",
    "        warning.value = 'Caracter invalid'\n",
    "    strength1.value='seguretat (metode 1): ' + str(0 if len(change['new']) < 8 else (2 if len(change['new']) > 13 else 1))\n",
    "    strength2.value='seguretat (metode 2): ' + str(pipe2.predict(format2(change['new']))[0])\n",
    "\n",
    "password.observe(on_value_change, names='value')\n",
    "display(warning, password, strength1, strength2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
