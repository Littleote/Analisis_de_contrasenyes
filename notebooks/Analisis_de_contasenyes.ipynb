{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5695a185",
   "metadata": {},
   "source": [
    "# CAS KAGGLE: Analisis de la seguretat de contrasenyes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55bbb0d",
   "metadata": {},
   "source": [
    "### David Candela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b3810",
   "metadata": {},
   "source": [
    "# Introducció\n",
    "\n",
    "Que faig i perquè."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2258b5",
   "metadata": {},
   "source": [
    "# 1. Netejar i visualitzar el dataset\n",
    "\n",
    "https://www.kaggle.com/bhavikbb/password-strength-classifier-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "Minuscules = [chr(c) for c in range(ord('a'), ord('z') + 1)]\n",
    "Majuscules = [chr(c) for c in range(ord('A'), ord('Z') + 1)]\n",
    "Xifres = [str(i) for i in range(10)]\n",
    "Especials = ['.', ';', '-', '_', '+', '*', '<', '>', '[', ']', '{', '}', \\\n",
    "             '(', ')', '@', '#', '$', '%', '&', '/', '\\\\', '?', '!', '=', \\\n",
    "             '^', '~', ' ']\n",
    "CaractersValids = Minuscules + Majuscules + Xifres + Especials\n",
    "\n",
    "def isValid(contrasenya):\n",
    "    try:\n",
    "        # Treure les contrasenyes amb caracters que no consideri valids\n",
    "        #   ja que no importa el format de descodificació especificat,\n",
    "        #   Python es incapaç de llegir correctament tots els diferents caràcters\n",
    "        #   caracters i sempre en surten de l'estil '\\x03', '\\x0f', '\\x8d'\n",
    "        #   o també §, ¶, ­, þ, ¤, ...\n",
    "        return all(c in CaractersValids for c in contrasenya)\n",
    "    except:\n",
    "        # Truere les contrasenyes que Pandas converteixi continuament a float\n",
    "        #   tot i que s'ha marcat la columna de passwords com strings\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e882b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = '../data/'\n",
    "data_name = 'data.csv'\n",
    "clean_name = 'clean_data.csv'\n",
    "data_file = path + data_name\n",
    "clean_file = path + clean_name\n",
    "regenerate_file = False\n",
    "\n",
    "if regenerate_file or not os.path.isfile(clean_file):\n",
    "    assert os.path.isfile(data_file)\n",
    "    # Saltarse les files on les dades no estiguin ben formategades\n",
    "    dataset = pd.read_csv(data_file, on_bad_lines='skip', encoding='utf-8', dtype={'password': str, 'strength': np.int64})\n",
    "    # Treure les dades que contenen caracters que no acceptem\n",
    "    dataset = dataset[dataset.apply(lambda s: isValid(s['password']), axis=1)]\n",
    "    # Guardar el nou dataset a un fitxer apart\n",
    "    dataset.to_csv(clean_file, index=False)\n",
    "    \n",
    "dataset = pd.read_csv(clean_file)\n",
    "dades = dataset.values\n",
    "contrasenyes = dades[:,0]\n",
    "dades_proteccio = dades[:,1].astype(np.int64)\n",
    "noms = dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af464d3",
   "metadata": {},
   "source": [
    "# 2. Extreure dades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87fb03",
   "metadata": {},
   "source": [
    "## Predictabilitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recompte(contrasenya, individual, predictabilitat):\n",
    "    c_ = ''\n",
    "    for c in contrasenya:\n",
    "        predictabilitat[c_][c] += 1\n",
    "        predictabilitat[c_]['total'] += 1\n",
    "        individual[c] += 1\n",
    "        individual['total'] += 1\n",
    "        c_ = c\n",
    "\n",
    "individual = {c:0 for c in CaractersValids + ['total']}\n",
    "predictabilitat = {c:{c:1 if not c == 'total' else len(CaractersValids) for c in CaractersValids + ['total']} for c in CaractersValids + ['']}\n",
    "\n",
    "for p in dades[:,0]:\n",
    "    recompte(p, individual, predictabilitat)\n",
    "\n",
    "individual_total = individual['total']\n",
    "predictabilitat_total = {c:predictabilitat[c]['total'] for c in predictabilitat.keys()}\n",
    "\n",
    "individual.pop('total')\n",
    "for k in predictabilitat.keys():\n",
    "    predictabilitat[k].pop('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "\n",
    "plt.subplots(figsize=(20, 18))\n",
    "plt.bar(individual.keys(), individual.values())\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(figsize=(20, 18))\n",
    "sns.heatmap([[e for e in d.values()] for d in predictabilitat.values()], \\\n",
    "            xticklabels=CaractersValids, yticklabels=CaractersValids + ['inici'], square=True, norm=LogNorm())\n",
    "plt.xlabel(\"Segon\")\n",
    "plt.ylabel(\"Primer\")\n",
    "plt.title(\"Sequencies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089e560",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def probabilitat_caracters(x):\n",
    "    res = 1\n",
    "    for c in x:\n",
    "        res *= individual.get(c, 1)\n",
    "    return res / (individual_total ** len(x))\n",
    "\n",
    "def probabilitat_sequencia(x):\n",
    "    res = 1\n",
    "    c_ = ''\n",
    "    for c in x:\n",
    "        if c not in CaractersValids:\n",
    "            continue\n",
    "        res *= predictabilitat[c_][c] / predictabilitat_total[c_]\n",
    "        c_ = c\n",
    "    return res\n",
    "\n",
    "def aleatorietat(x):\n",
    "    res = 1\n",
    "    c_ = ''\n",
    "    for c in x:\n",
    "        if c not in CaractersValids:\n",
    "            continue\n",
    "        res *= individual[c] / predictabilitat[c_][c] * predictabilitat_total[c_] / individual_total\n",
    "        c_ = c\n",
    "    return res\n",
    "\n",
    "def llargada(x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "dades_caracters = np.vectorize(probabilitat_caracters)(contrasenyes)\n",
    "dades_sequencia = np.vectorize(probabilitat_sequencia)(contrasenyes)\n",
    "dades_aleatorietat = np.vectorize(aleatorietat)(contrasenyes)\n",
    "dades_llargada = np.vectorize(llargada)(contrasenyes)\n",
    "\n",
    "dades_predictabilitat = np.stack((dades_caracters, dades_sequencia, dades_aleatorietat, dades_llargada, dades_proteccio), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP = dades_predictabilitat\n",
    "MDP = pd.DataFrame(data=DP, columns=['caracters', 'sequencia', 'aleatorietat', 'llargada', 'proteccio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=MDP, x=\"caracters\", hue=\"proteccio\", multiple=\"layer\", log_scale=True, binrange=[-39, -7], element=\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292135b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=MDP, x=\"sequencia\", hue=\"proteccio\", multiple=\"layer\", log_scale=True, binrange=[-36, -5], element=\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73070de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=MDP, x=\"aleatorietat\", hue=\"proteccio\", multiple=\"layer\", log_scale=True, binrange=[-10, 6], element=\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=MDP, x=\"llargada\", hue=\"proteccio\", multiple=\"stack\", discrete=True, binrange=[1, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633b8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=dades_caracters, y=dades_llargada, c=dades_proteccio, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(1e-60, 1e-4)\n",
    "plt.ylim(0, 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8042c9e",
   "metadata": {},
   "source": [
    "### Probar eficacia de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subset(X, y, p=1, index=None):\n",
    "    if p == 1:\n",
    "        l = len(y)\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        values = {u: l / len(unique) / c for u, c in zip(unique, counts)}\n",
    "        return X, y, np.array([values[yi] for yi in y])\n",
    "    elif type(p) == list:\n",
    "        \n",
    "        return\n",
    "    else:\n",
    "        l = len(y)\n",
    "        new_l = int(l * p)\n",
    "        if index == None:\n",
    "            index = np.array([i for i in range(l)])\n",
    "        ind = np.random.choice(index, new_l, replace=False)\n",
    "        index = np.setdiff1d(index, ind)\n",
    "        new_X = X[ind]\n",
    "        new_y = y[ind]\n",
    "        unique, counts = np.unique(new_y, return_counts=True)\n",
    "        values = {u: new_l / len(unique) / c for u, c in zip(unique, counts)}\n",
    "        return new_X, new_y, np.array([values[yi] for yi in new_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac416db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class oneVsRest:\n",
    "    def __init__(self, model, **kwargs):\n",
    "        self.model = model\n",
    "        self.modelArgs = kwargs\n",
    "        \n",
    "    def fit(self, x, y, w=None):\n",
    "        yTo0 = np.copy(y)\n",
    "        yTo0[yTo0 > 0] = -1\n",
    "        yTo0[yTo0 != -1] = 1\n",
    "        self.classTo0 = self.model(**self.modelArgs)\n",
    "        self.classTo0.fit(x, yTo0, sample_weight=w)\n",
    "        yTo1 = np.copy(y)\n",
    "        yTo1[yTo1 > 1] = -1\n",
    "        yTo1[yTo1 != -1] = 1\n",
    "        self.classTo1 = self.model(**self.modelArgs)\n",
    "        self.classTo1.fit(x, yTo1, sample_weight=w)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return (2 - self.classTo0.predict(x) - self.classTo1.predict(x)) / 2\n",
    "\n",
    "class LogPipe:\n",
    "    err = 1e-200\n",
    "    def __init__ (self, columns):\n",
    "        self.column_transform = columns\n",
    "    \n",
    "    def fit (self, X, **args):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, copy=True):\n",
    "        if copy == True:\n",
    "            X_tr = np.copy(X)\n",
    "        else:\n",
    "            X_tr = X\n",
    "        X_tr[:, self.column_transform] = np.log(X_tr[:, self.column_transform] + LogPipe.err)\n",
    "        return X_tr\n",
    "    \n",
    "    def fit_transform(self, X, y=None, copy=True, **args):\n",
    "        return self.transform(X, copy)\n",
    "\n",
    "def regression(x, y, model=linear_model.LogisticRegression, w=None, **kwargs):\n",
    "    # Creem un objecte de regressió de sklearn\n",
    "    regr = oneVsRest(model, **kwargs)\n",
    "\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(x, y, w=w)\n",
    "\n",
    "    # Retornem el model entrenat\n",
    "    return regr\n",
    "\n",
    "def visualize_confusion_matrix(y_pred, y_real):\n",
    "    #mostra la matriu de confusió\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "    plt.subplots(figsize=(10, 6))\n",
    "    sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dades_t, objectiu_t, w_t = make_subset(DP[:, 0:4], DP[:, 4], .2)\n",
    "dades_cv, objectiu_cv, w_cv = make_subset(DP[:, 0:4], DP[:, 4], 1)\n",
    "log_norm = LogPipe([0, 1, 2]).fit(dades_t)\n",
    "norm = preprocessing.StandardScaler().fit(log_norm.transform(dades_t))\n",
    "r = regression(norm.transform(log_norm.transform(dades_t)), objectiu_t, w=w_t, model=svm.LinearSVC, max_iter=1e6)\n",
    "# linear_model.LogisticRegression\n",
    "# svm.LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "prediccio = r.predict(norm.transform(log_norm.transform(dades_cv)))\n",
    "print(f'Accuracy: {sum(objectiu_cv==prediccio) / len(prediccio)}')\n",
    "print(f'Weighted accuracy: {sum(w_cv * (objectiu_cv==prediccio)) / len(prediccio)}')\n",
    "visualize_confusion_matrix(prediccio, objectiu_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b06d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dades_t, objectiu_t, w_t = make_subset(DP[:, 0:3], DP[:, 4], .2)\n",
    "dades_cv, objectiu_cv, w_cv = make_subset(DP[:, 0:3], DP[:, 4], 1)\n",
    "log_norm = LogPipe([0, 1, 2]).fit(dades_t)\n",
    "norm = preprocessing.StandardScaler().fit(log_norm.transform(dades_t))\n",
    "r = regression(norm.transform(log_norm.transform(dades_t)), objectiu_t, model=svm.LinearSVC, max_iter=1e6)\n",
    "# linear_model.LogisticRegression\n",
    "# svm.LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "prediccio = r.predict(norm.transform(log_norm.transform(dades_cv)))\n",
    "print(f'Accuracy: {sum(objectiu_cv==prediccio) / len(prediccio)}')\n",
    "print(f'Weighted accuracy: {sum(w_cv * (objectiu_cv==prediccio)) / len(prediccio)}')\n",
    "visualize_confusion_matrix(prediccio, objectiu_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c408e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('log', LogPipe([0, 1, 2])), ('scaler', preprocessing.StandardScaler()), ('model', linear_model.LogisticRegression())])\n",
    "\n",
    "Y_cv, W_cv, prediccio = [], [], []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(DP):\n",
    "    x_t, y_t, w_t = make_subset(DP[train_index, 0:3], DP[train_index, 4])\n",
    "    x_cv, y_cv, w_cv = make_subset(DP[test_index, 0:3], DP[test_index, 4])\n",
    "    pipe.fit(x_t, y_t, model__sample_weight=w_t)\n",
    "\n",
    "    Y_cv.append(y_cv)\n",
    "    W_cv.append(w_cv)\n",
    "    prediccio.append(pipe.predict(x_cv))\n",
    "    \n",
    "Y_cv = np.concatenate(Y_cv)\n",
    "W_cv = np.concatenate(W_cv)\n",
    "prediccio = np.concatenate(prediccio)\n",
    "\n",
    "print(f'Accuracy: {sum(Y_cv==prediccio) / len(prediccio)}')\n",
    "print(f'Weighted accuracy: {sum(W_cv * (Y_cv==prediccio)) / len(prediccio)}')\n",
    "visualize_confusion_matrix(prediccio, Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10, 6))\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "plt.scatter(x=dades_llargada, y=dades_proteccio)\n",
    "plt.show()\n",
    "\n",
    "#Feature tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb799824",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(min(dades_llargada[dades_proteccio == i]), max(dades_llargada[dades_proteccio == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "prediccio = np.array([0 if len(x) < 8 else (2 if len(x) > 13 else 1) for x in contrasenyes])\n",
    "visualize_confusion_matrix(prediccio, dades_proteccio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "password = widgets.Text()\n",
    "probabilitat = widgets.Label()\n",
    "sequential = widgets.Label()\n",
    "randomnes = widgets.Label()\n",
    "strength = widgets.Label()\n",
    "\n",
    "def form(x):\n",
    "    return np.array([[probabilitat_caracters(x), probabilitat_sequencia(x), aleatorietat(x), llargada(x)]])\n",
    "\n",
    "def on_value_change(change):\n",
    "    probabilitat.value='probability: ' + str(probabilitat_caracters(change['new']))\n",
    "    sequential.value='sequential: ' + str(probabilitat_sequencia(change['new']))\n",
    "    randomnes.value='randomnes: ' + str(aleatorietat(change['new']))\n",
    "    strength.value='strength: ' + str(0 if len(change['new']) < 8 else (2 if len(change['new']) > 13 else 1))\n",
    "\n",
    "password.observe(on_value_change, names='value')\n",
    "display(password, probabilitat, sequential, randomnes, strength)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
